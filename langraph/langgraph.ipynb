{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "badcc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "    return input_1 + \" First Function \"\n",
    "\n",
    "def function_2(input_2):\n",
    "    return input_2 + \"to Second Function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8b7658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddf0d93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b80ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ab2ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4a59828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55cc5a5",
   "metadata": {},
   "source": [
    "the graph state that has been created below are thevery useful ttool swhen you want data in strucure form not intvery chaos maaner ,, the system youy are dreaming of will be creeated ont he top of this only you dont need to be  woory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80613d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    # The state will hold a single string message\n",
    "    message: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "554e95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for function_1\n",
    "def node_1_wrapper(state: GraphState) -> dict:\n",
    "    # 1. Get the current message from the state\n",
    "    current_message = state['message']\n",
    "    # 2. Call your original function with that message\n",
    "    new_message = function_1(current_message)\n",
    "    # 3. Return a dictionary to update the state\n",
    "    return {\"message\": new_message}\n",
    "\n",
    "# Wrapper for function_2\n",
    "def node_2_wrapper(state: GraphState) -> dict:\n",
    "    current_message = state['message']\n",
    "    new_message = function_2(current_message)\n",
    "    return {\"message\": new_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9ff9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Define a Langchain graph\n",
    "workflow = StateGraph(list)\n",
    "\n",
    "workflow.add_node(\"node_1\", function_1)\n",
    "workflow.add_node(\"node_2\", function_2)\n",
    "\n",
    "workflow.add_edge('node_1', 'node_2')\n",
    "\n",
    "workflow.set_entry_point(\"node_1\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a3d9b",
   "metadata": {},
   "source": [
    "the boove code is npt workng for the reason that graph class has been removed completely from the laggraph .. nowit haas been only state graph however we will wite cod eto complete the hands on ractice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86e1de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are you? First Function to Second Function\n"
     ]
    }
   ],
   "source": [
    "initial_input = \"how are you?\"\n",
    "final_result = app.invoke(initial_input)\n",
    "\n",
    "print(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75ffb6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'node_1':\n",
      "---\n",
      "I am moving from First Function \n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'node_2':\n",
      "---\n",
      "I am moving from First Function to Second Function\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = 'I am moving from'\n",
    "for output in app.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e4ef4",
   "metadata": {},
   "source": [
    "now the function 1 nad funcction 2 itself are indepedent to call another function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b1ba85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f0a6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ccad8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper for function_1\n",
    "def node_1_wrapper(state: GraphState) -> dict:\n",
    "    # 1. Get the current message from the state\n",
    "    current_message = state['message']\n",
    "    # 2. Call your original function with that message\n",
    "    new_message = function_1(current_message)\n",
    "    # 3. Return a dictionary to update the state\n",
    "    return {\"message\": new_message}\n",
    "\n",
    "# Wrapper for function_2\n",
    "def node_2_wrapper(state: GraphState) -> dict:\n",
    "    current_message = state['message']\n",
    "    new_message = function_2(current_message)\n",
    "    return {\"message\": new_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "071643ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state: list):\n",
    "    # Get the user query, which is the last item in the state list\n",
    "    user_query = state[-1]\n",
    "    \n",
    "    complete_query = \"Your task is to provide only the topic based on the user query. \\\n",
    "        Only output the topic among: [Japan , Sports]. Don't include reasoning. Following is the user query: \" + user_query\n",
    "    \n",
    "    response = llm.invoke(complete_query)\n",
    "    # The return value will be APPENDED to the state list\n",
    "    return response.content\n",
    "\n",
    "# FIX 2: This function must also accept the entire state (list)\n",
    "# and get the topic from the last element.\n",
    "def function_2(state: list):\n",
    "    # Get the topic from the Agent, which is now the last item in the list\n",
    "    topic_from_agent = state[-1]\n",
    "    \n",
    "    TOPIC_UPPER = topic_from_agent.upper()\n",
    "    response = f\"Here is the topic in UPPER case: {TOPIC_UPPER}\"\n",
    "    # This return value will also be APPENDED to the state list\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31e87236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Langchain graph\n",
    "workflow = StateGraph(list)\n",
    "\n",
    "workflow.add_node(\"Agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "\n",
    "workflow.add_edge('Agent', 'tool')\n",
    "\n",
    "workflow.set_entry_point(\"Agent\")\n",
    "workflow.set_finish_point(\"tool\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac16f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Final State List---\n",
      "Here is the topic in UPPER case: N\n"
     ]
    }
   ],
   "source": [
    "final_state = app.invoke([\"who is the prime minister of Japan?\"])\n",
    "\n",
    "print(\"---Final State List---\")\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9949977",
   "metadata": {},
   "source": [
    "custom token counte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "421b17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3(input):\n",
    "    token=input.split()\n",
    "    token_number=len(token)\n",
    "    token_number=f\"total token {token_number}\"\n",
    "    return token_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc4f02b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define a Langchain graph\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m workflow \u001b[38;5;241m=\u001b[39m \u001b[43mGraph\u001b[49m()\n\u001b[0;32m      4\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m, function_1)\n\u001b[0;32m      5\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_counter\u001b[39m\u001b[38;5;124m\"\u001b[39m, function_3)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Graph' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a Langchain graph\n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"Agent\", function_1)\n",
    "workflow.add_node(\"token_counter\", function_3)\n",
    "\n",
    "workflow.add_edge('Agent', 'token_counter')\n",
    "\n",
    "workflow.set_entry_point(\"Agent\")\n",
    "workflow.set_finish_point(\"token_counter\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a05fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke(\"what is the name of the game?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4211ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb3b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGSMITH_TRACING = os.getenv(\"LANGSMITH_TRACING\")\n",
    "LANGSMITH_ENDPOINT = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "# TRAVILY_PROJECT = os.getenv(\"TRAVILY_PROJECT\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfb7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ea7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5df0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run--7d4757bb-695a-4717-9f42-83e717beb7c3-0', usage_metadata={'input_tokens': 1, 'output_tokens': 11, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cd68a",
   "metadata": {},
   "source": [
    "till now we ere using tool and creating agensts with the predefined thngs in langchaiin such  as react self ask tooll calling these all were predefinsed inthe langchain library, now we will learn to create agents from scratch so here we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1fc27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self,system=\"\"):\n",
    "        self.system=system\n",
    "        self.message=[]\n",
    "        if self.system:\n",
    "            self.message.append({\"role\":\"system\",\"content\":system})\n",
    "    def __call__(self,message):\n",
    "        self.message.append({\"role\":\"user\",\"content\":message})\n",
    "        result=self.execute()\n",
    "        self.message.append({\"role\":\"assistant\",\"content\":result})\n",
    "        return result\n",
    "        \n",
    "    def execute(self):\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "        result = llm.invoke(self.message)\n",
    "        return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95ac819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bot=Chatbot(\"you are a helpful assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa20e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bot(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ccf236b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'you are a helpful assistant'},\n",
       " {'role': 'user', 'content': 'hi'},\n",
       " {'role': 'assistant', 'content': 'Hi there! How can I help you today?'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1096ad8",
   "metadata": {},
   "source": [
    "the below regulart expression function is created for the identification of action term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdd0cb",
   "metadata": {},
   "source": [
    "Understand the Regular expression\n",
    "Pattern Breakdown:\n",
    "\n",
    "^: This matches the start of a string. It means the string must begin with what follows.\n",
    "Action:: This is a literal match. It means the string must have the text \"Action:\" at the beginning.\n",
    "(\\w+):\n",
    "The parentheses () define a capture group. This allows you to extract part of the string that matches this section.\n",
    "\\w+ matches one or more word characters (letters, digits, and underscores). This will capture a word that follows \"Action:\".\n",
    ":: This is a literal colon that separates the word matched by (\\w+) from the rest of the string.\n",
    "(.*):\n",
    "This is another capture group, where .* matches any character (.) zero or more times (*), which means it captures everything that comes after the second colon.\n",
    "What does it do?\n",
    "This regex is looking for a string that:\n",
    "\n",
    "Starts with the text \"Action:\".\n",
    "Has a word right after it, separated by a colon.\n",
    "Then, after another colon, it captures everything that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4da3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "action_re = re.compile('^Action: (\\w+): (.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a104972",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop your output an Answer.\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you..\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "\n",
    "Your available actions are:\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point\n",
    "syntax if necessary\n",
    "\n",
    "wikipedia:\n",
    "e.g. wikipedia: Django\n",
    "Returns a summary from searching Wikipedia\n",
    "\n",
    "simon_blog_search:\n",
    "e.g. simon_blog_search: Python\n",
    "Search Simon's blog for that term\n",
    "\n",
    "Example session:\n",
    "Question: What is the capital of France?\n",
    "Thought: I should look up France on Wikipedia\n",
    "Action: wikipedia: France\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "Observation: France is a country. The capital is Paris.\n",
    "\n",
    "You then output:\n",
    "Answer: The capital of France is Paris\n",
    "\n",
    "Please Note: if you get basic conversation questions like \"hi\",\"hello\",\"how are you?\",\\n\n",
    "you have to answer \"hi\",\"hello\",\"i am good\".\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43200ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "def wikipedia(query):\n",
    "    response = httpx.get(\"https://en.wikipedia.org/w/api.php\", params={\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": query,\n",
    "        \"format\": \"json\"\n",
    "    })\n",
    "    return response.json()[\"query\"][\"search\"][0][\"snippet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51893a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "def simon_blog_search(query):\n",
    "    response = httpx.get(\"https://datasette.simonwillison.net/simonwillisonblog.json\", params={\n",
    "        \"sql\": \"\"\"\n",
    "        select\n",
    "          blog_entry.title || ': ' || substr(html_strip_tags(blog_entry.body), 0, 1000) as text,\n",
    "          blog_entry.created\n",
    "        from\n",
    "          blog_entry join blog_entry_fts on blog_entry.rowid = blog_entry_fts.rowid\n",
    "        where\n",
    "          blog_entry_fts match escape_fts(:q)\n",
    "        order by\n",
    "          blog_entry_fts.rank\n",
    "        limit\n",
    "          1\n",
    "        \"\"\".strip(),\n",
    "        \"_shape\": \"array\",\n",
    "        \"q\": query,\n",
    "    })\n",
    "    return response.json()[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "947e074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate(number):\n",
    "    return eval(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df64d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_actions = {\n",
    "    \"wikipedia\": wikipedia,\n",
    "    \"calculate\": calculate,\n",
    "    \"simon_blog_search\": simon_blog_search\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dca4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(question,max_turns=5):\n",
    "    i = 0\n",
    "    bot = Chatbot(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [action_re.match(a) for a in result.split('\\n') if action_re.match(a)]\n",
    "        if actions:\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(f\"Unknown action: {action}: {action_input}\")\n",
    "            print(\" -- running {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = f\"Observation: {observation}\"\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca11fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Chatbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d784e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: i am good'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot(\"how are you??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d5039b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thought: I need to describe my job.\\n\\nAction: None\\n\\nPAUSE\\n\\nAnswer: I am a large language model, trained to provide helpful and informative responses to a wide range of queries and tasks.  I can generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way, even if they are open ended, challenging, or strange.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot(\"what is your job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ded90162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: hi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: hi'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d433f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up France on Wikipedia\n",
      "Action: wikipedia: France\n",
      "PAUSE\n",
      " -- running wikipedia France\n",
      "Observation: <span class=\"searchmatch\">France</span>, officially the <span class=\"searchmatch\">French</span> Republic, is a country primarily located in Western Europe. Its overseas regions and territories include <span class=\"searchmatch\">French</span> Guiana in\n",
      "Answer: The capital of France is Paris.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: The capital of France is Paris.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "522f7a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to calculate 5 + 5.\n",
      "Action: calculate: 5 + 5\n",
      "PAUSE\n",
      " -- running calculate 5 + 5\n",
      "Observation: 10\n",
      "Answer: Five plus five is 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: Five plus five is 10.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"five plus five   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dc78af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should search Simon's blog for \"AI\".\n",
      "Action: simon_blog_search: AI\n",
      "PAUSE\n",
      " -- running simon_blog_search AI\n",
      "Observation: Talking AI and jobs with Natasha Zouves for News Nation: I was interviewed by News Nation's Natasha Zouves about the very complicated topic of how we should think about AI in terms of threatening our jobs and careers. I previously talked with Natasha two years ago about Microsoft Bing.\n",
      "\n",
      "I'll be honest: I was nervous about this one. I'm not an economist and I didn't feel confident talking about this topic!\n",
      "\n",
      "I do find the challenge of making recent advances in AI and LLMs accessible to a general audience absolutely fascinating though, so I took the risk and agreed to the interview.\n",
      "\n",
      "I think it came out very well. The full hour long video is now available on the News Nation YouTube channel, or as an audio podcast on iTunes or on Spotify.\n",
      "\n",
      " \n",
      "\n",
      "I made my own transcript of the video (using MacWhisper) and fed it into the new Claude Opus 4 model to see if it could do a good job of turning that into an outline of the episode, with links to segments, short summaries and illustrative quotes. It did such a good job that I'm including it here \n",
      "Answer: Yes, Simon has written about AI on his blog, including an interview he did with News Nation about AI and jobs.  He also used AI tools to help process the transcript of the interview.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: Yes, Simon has written about AI on his blog, including an interview he did with News Nation about AI and jobs.  He also used AI tools to help process the transcript of the interview.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"has simon written over ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2be226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

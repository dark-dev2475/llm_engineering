{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae7152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagan\\OneDrive\\Desktop\\llm_learning\\langchain\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # This will print the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a05bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"c:\\\\Users\\\\gagan\\\\OneDrive\\\\Desktop\\\\llm_learning\\\\langchain\\\\.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192fd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGSMITH_TRACING = os.getenv(\"LANGSMITH_TRACING\")\n",
    "LANGSMITH_ENDPOINT = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "LANGSMITH_PROJECT = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "# TRAVILY_PROJECT = os.getenv(\"TRAVILY_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17550538",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e053428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY hao kya: AIzaSyDS4D8P-5UhRuCQcNV5bs5-jF8BKJD7WL4\n",
      "more:  true https://api.smith.langchain.com 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 project1 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\n"
     ]
    }
   ],
   "source": [
    "print(\"GOOGLE_API_KEY hao kya:\", GOOGLE_API_KEY)\n",
    "print(\"more: \",LANGSMITH_TRACING, LANGSMITH_ENDPOINT, LANGSMITH_API_KEY, LANGSMITH_PROJECT,TAVILY_API_KEY)\n",
    "# print(\"Model object:\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f0a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df82d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\",convert_system_message_to_human=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f38add",
   "metadata": {},
   "outputs": [],
   "source": [
    "message=[SystemMessage(content=\"you are a nice bot\"),HumanMessage(content=\"hi how are yoou?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8392e8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As a large language model, I don\\'t experience emotions or feelings like \"good\" or \"bad.\"  However, I\\'m functioning as expected and ready to assist you.  How can I help you today?  Perhaps you\\'d like me to write a story, answer a question, or translate something?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run--456f6497-0f57-44ca-b2e0-e798a11fb2cc-0', usage_metadata={'input_tokens': 11, 'output_tokens': 66, 'total_tokens': 77, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae3ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a617e061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a large language model, I don\\'t experience emotions or feelings like \"good\" or \"bad.\"  However, I\\'m functioning as expected and ready to assist you.  How can I help you today?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=model.invoke(message)\n",
    "parser.invoke(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea54d70",
   "metadata": {},
   "source": [
    "lcel chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bbd5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=model|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d20c0759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a large language model, I don\\'t experience emotions or feelings like \"good\" or \"bad\".  However, I\\'m functioning as expected and ready to assist you.  How can I help you today?  Perhaps you have a question you\\'d like me to answer, or a task you\\'d like me to perform?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13bea0",
   "metadata": {},
   "source": [
    "prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8944336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f05ace4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Translate this into {language},only output the translation.\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c65708c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=prompt_template.invoke({\"language\":\"hindi\",\"text\":\"i am learning hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d29787dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='मैं हिंदी सीख रहा हूँ / मैं हिंदी सीख रही हूँ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run--54b11a96-02fa-4141-83b8-74ceaf2f59cf-0', usage_metadata={'input_tokens': 14, 'output_tokens': 19, 'total_tokens': 33, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537729a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मैं हिंदी सीख रहा हूँ / मैं हिंदी सीख रही हूँ'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73b33e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate this into hindi,only output the translation.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i am learning hindi', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efca6c1",
   "metadata": {},
   "source": [
    "chaining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "804ed702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'apprends le français.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2=prompt_template|model|parser\n",
    "chain2.invoke({\"language\":\"french\",\"text\":\"i am learning french\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277e347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "358e2c43",
   "metadata": {},
   "source": [
    "# Test Tavily API Key setup\n",
    "print(\"TAVILY_API_KEY loaded:\", TAVILY_API_KEY)\n",
    "print(\"TAVILY_API_KEY in environment:\", os.environ.get('TAVILY_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a7a11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbf18fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01c742a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What's a 'node' in LangGraph?\",\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.ionio.ai/blog/a-comprehensive-guide-about-langgraph-code-included',\n",
       "   'title': 'A Comprehensive Guide About Langgraph: Code Included - Ionio',\n",
       "   'content': 'A node can be any function or tool your agent uses in langgraph and these nodes are connected with other nodes using edges. Every workflow ends with a “END” node in langgraph which shows the end of workflow. You also need to define a starting node which will be the starting point of your workflow.',\n",
       "   'score': 0.9049283,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "   'title': \"Introduction to LangGraph: A Beginner's Guide - Medium\",\n",
       "   'content': '*   **Stateful Graph:** LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. Image 10: Introduction to AI Agent with LangChain and LangGraph: A Beginner’s Guide Image 18: How to build LLM Agent with LangGraph\\u200a—\\u200aStateGraph and Reducer Image 20: Simplest Graphs using LangGraph Framework Image 24: Building a ReAct Agent with Langgraph: A Step-by-Step Guide Image 28: Building an Agentic RAG with LangGraph: A Step-by-Step Guide',\n",
       "   'score': 0.65252984,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.7}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f381ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"You are a helpful assistant. You have access to a search tool. \"\n",
    "         \"Use it to answer questions about real-time information like weather.\"),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6b4a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=MemorySaver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d29f00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TavilySearchResults initialized successfully\n",
      "Tools list: [TavilySearch(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tavily search with error handling\n",
    "try:\n",
    "    search = TavilySearch(max_results=2)\n",
    "    print(\"TavilySearchResults initialized successfully\")\n",
    "    tools = [search]\n",
    "    print(\"Tools list:\", tools)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing TavilySearchResults: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7440276d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily search test result: {'query': 'weather in Delhi', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Delhi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Delhi', 'region': 'Ontario', 'country': 'Canada', 'lat': 42.85, 'lon': -80.5, 'tz_id': 'America/Toronto', 'localtime_epoch': 1754627769, 'localtime': '2025-08-08 00:36'}, 'current': {'last_updated_epoch': 1754627400, 'last_updated': '2025-08-08 00:30', 'temp_c': 19.0, 'temp_f': 66.2, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 11.6, 'wind_kph': 18.7, 'wind_degree': 176, 'wind_dir': 'S', 'pressure_mb': 1023.0, 'pressure_in': 30.21, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 88, 'cloud': 75, 'feelslike_c': 19.0, 'feelslike_f': 66.2, 'windchill_c': 21.8, 'windchill_f': 71.3, 'heatindex_c': 24.2, 'heatindex_f': 75.5, 'dewpoint_c': 19.4, 'dewpoint_f': 66.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 22.1, 'gust_kph': 35.6}}\", 'score': 0.9406763, 'raw_content': None}, {'url': 'https://timesofindia.indiatimes.com/weather/new-delhi-weather-forecast-today/110011', 'title': 'New Delhi Weather Forecast 8 Aug 2025 - The Times of India', 'content': \"Today's Weather in New Delhi: In New Delhi today, the weather is expected to be Haze with a maximum temperature of 34°C and a minimum of 28°C. Sunrise in\", 'score': 0.93265617, 'raw_content': None}], 'response_time': 0.88}\n"
     ]
    }
   ],
   "source": [
    "# Test Tavily search directly\n",
    "try:\n",
    "    test_result = search.invoke(\"weather in Delhi\")\n",
    "    print(\"Tavily search test result:\", test_result)\n",
    "except Exception as e:\n",
    "    print(f\"Error testing Tavily search: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92763f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent executor created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create agent with error handling\n",
    "try:\n",
    "    agent = create_react_agent(model, tools, checkpointer=memory,prompt=prompt)\n",
    "    agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    checkpointer=memory,\n",
    "    verbose=True  # Use verbose=True to see the agent's thoughts\n",
    ")\n",
    "    print(\"Agent executor created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88776aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"thre123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "836fc7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting agent conversation ===\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new None chain...\u001b[0m\n",
      "Error during agent execution: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Starting agent conversation ===\")\n",
    "try:\n",
    "    for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"hey i live in allahabad\")]},\n",
    "        config\n",
    "    ):\n",
    "        print(\"Chunk:\", chunk)\n",
    "        print(\"---\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during agent execution: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44275a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new None chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m agent_executor\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you tell me the weather of where i live\u001b[39m\u001b[38;5;124m\"\u001b[39m)]},\n\u001b[0;32m      3\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig\n\u001b[0;32m      4\u001b[0m ):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk)\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\chain\\lib\\site-packages\\langchain\\agents\\agent.py:1795\u001b[0m, in \u001b[0;36mAgentExecutor.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m   1784\u001b[0m iterator \u001b[38;5;241m=\u001b[39m AgentExecutorIterator(\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1794\u001b[0m )\n\u001b[1;32m-> 1795\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m iterator\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\chain\\lib\\site-packages\\langchain\\agents\\agent_iterator.py:200\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_should_continue(\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_elapsed,\n\u001b[0;32m    196\u001b[0m ):\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     next_step_seq: NextStepOutput \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_to_tool_map,\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_mapping,\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs,\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_steps,\n\u001b[0;32m    205\u001b[0m         run_manager,\n\u001b[0;32m    206\u001b[0m     ):\n\u001b[0;32m    207\u001b[0m         next_step_seq\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;66;03m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;66;03m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\chain\\lib\\site-packages\\langchain\\agents\\agent.py:1352\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1351\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1352\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1353\u001b[0m         intermediate_steps,\n\u001b[0;32m   1354\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1356\u001b[0m     )\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\chain\\lib\\site-packages\\langchain\\agents\\agent.py:455\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    457\u001b[0m             final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\chain\\lib\\site-packages\\langgraph\\pregel\\main.py:2518\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2501\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m   2502\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2503\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2504\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name()),\n\u001b[0;32m   2505\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   2506\u001b[0m )\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2508\u001b[0m     \u001b[38;5;66;03m# assign defaults\u001b[39;00m\n\u001b[0;32m   2509\u001b[0m     (\n\u001b[0;32m   2510\u001b[0m         stream_modes,\n\u001b[0;32m   2511\u001b[0m         output_keys,\n\u001b[0;32m   2512\u001b[0m         interrupt_before_,\n\u001b[0;32m   2513\u001b[0m         interrupt_after_,\n\u001b[0;32m   2514\u001b[0m         checkpointer,\n\u001b[0;32m   2515\u001b[0m         store,\n\u001b[0;32m   2516\u001b[0m         cache,\n\u001b[0;32m   2517\u001b[0m         durability_,\n\u001b[1;32m-> 2518\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2524\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdurability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m durability \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2528\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2529\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`durability` has no effect when no checkpointer is present.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2530\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\chain\\lib\\site-packages\\langgraph\\pregel\\main.py:2390\u001b[0m, in \u001b[0;36mPregel._defaults\u001b[1;34m(self, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability)\u001b[0m\n\u001b[0;32m   2388\u001b[0m     checkpointer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointer\n\u001b[0;32m   2389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpointer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(CONF):\n\u001b[1;32m-> 2390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2391\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpointer requires one or more of the following \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2392\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys: thread_id, checkpoint_ns, checkpoint_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2393\u001b[0m     )\n\u001b[0;32m   2394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CONFIG_KEY_RUNTIME \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(CONF, {}):\n\u001b[0;32m   2395\u001b[0m     store: BaseStore \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_RUNTIME]\u001b[38;5;241m.\u001b[39mstore\n",
      "\u001b[1;31mValueError\u001b[0m: Checkpointer requires one or more of the following 'configurable' keys: thread_id, checkpoint_ns, checkpoint_id"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"can you tell me the weather of where i live\")]},\n",
    "    config=config\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fdc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
